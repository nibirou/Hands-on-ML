{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896cb86b",
   "metadata": {},
   "source": [
    "# K近邻算法\n",
    "K近邻算法（k-nearest neighbor, KNN）是一种最简单的机器学习算法，也是一个最基本的分类和回归算法，不涉及庞大复杂的神经网络。\n",
    "同一种类的数据之间特征更为相似，而不同种类的数据之间特征差别更大。\n",
    "\n",
    "## 3.1 KNN算法的原理\n",
    "KNN会先观察与该样本点距离最近的K个样本，统计这些样本所属的类别。然后，将当前样本归到出现次数最多的类中。\n",
    "KNN的基本思路是让当前样本服从K个邻居中的多数分类，当K的大小变化时，由于邻居的数量变化，其多数类别也可能会变化，从而改变当前样本的分类判断。因此，决定K的大小是KNN算法中最重要的部分。\n",
    "\n",
    "直观上来说，当K的取值太小时，分类结果很容易受到待分类样本周围的噪声数据影响。\n",
    "当K的取值太大时，又容易将远处一些不相关的样本包含进来。\n",
    "\n",
    "## 3.2 基于KNN算法完成手写数字识别分类任务\n",
    "MNIST是手写数字数据集，包含很多手写数字0-9的黑白图像，每幅图像的尺寸是28*28像素。每个像素用1或0表示，1代表黑色背景像素，0代表手写数字像素。\n",
    "\n",
    "### 具体操作\n",
    "把每个数据集都按8：2的比例随机划分成训练集和测试集，在训练集上应用KNN算法，然后在测试集上测试算法"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
